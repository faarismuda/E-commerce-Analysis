{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wADwK78DCz"
      },
      "source": [
        "# Proyek Analisis Data: E-Commerce Public Dataset\n",
        "- **Nama:** Faaris Muda Dwi Nugraha\n",
        "- **Email:** faarismudadwinugraha@gmail.com / faarismudawork@gmail.com\n",
        "- **ID Dicoding:** faarismuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE0raob58DC0"
      },
      "source": [
        "## Menentukan Pertanyaan Bisnis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmQeQ5YF8DC0"
      },
      "source": [
        "**1. \"Bagaimana performa rata-rata waktu pengiriman di tiap kota pada tahun 2017, dan apakah ada kota dengan waktu pengiriman lebih dari 10 hari yang dapat memperburuk kepuasan pelanggan?\"**\n",
        "\n",
        "- **Specific**: Fokus pada analisis waktu pengiriman di tiap kota pada tahun 2017.\n",
        "- **Measurable**: Mengukur rata-rata waktu pengiriman dan identifikasi kota dengan waktu pengiriman lebih dari 10 hari.\n",
        "- **Action-oriented**: Dapat digunakan untuk mengidentifikasi area yang memerlukan perbaikan dalam hal logistik dan pengiriman.\n",
        "- **Relevant**: Mengoptimalkan waktu pengiriman untuk meningkatkan pengalaman pelanggan dan kepuasan.\n",
        "- **Time-bound**: Membatasi analisis pada tahun 2017.\n",
        "\n",
        "**Teknik Analisis Lanjutan**:\n",
        "- **Geospatial Analysis**: Menganalisis lokasi dan waktu pengiriman menggunakan data dari `orders_dataset.csv` dan `geolocation_dataset.csv`.\n",
        "    - Membuat **heatmap** untuk menunjukkan waktu pengiriman di setiap kota.\n",
        "    - Menghitung **rata-rata waktu pengiriman** per kota dan mengidentifikasi **outlier**.\n",
        "\n",
        "\n",
        "**2. \"Apa hubungan antara frekuensi pembelian pelanggan dan total pengeluaran mereka di tahun 2017, dan bagaimana pola ini memengaruhi segmentasi pelanggan yang paling menguntungkan?\"**\n",
        "\n",
        "- **Specific**: Fokus pada analisis frekuensi pembelian dan total pengeluaran pelanggan di tahun 2017.\n",
        "- **Measurable**: Menghitung frekuensi pembelian dan total pengeluaran pelanggan.\n",
        "- **Action-oriented**: Membantu dalam membuat strategi pemasaran yang ditujukan untuk segmen pelanggan yang menguntungkan.\n",
        "- **Relevant**: Penting untuk strategi retensi pelanggan dan peningkatan pendapatan.\n",
        "- **Time-bound**: Fokus pada data tahun 2017.\n",
        "\n",
        "**Teknik Analisis Lanjutan**:\n",
        "- **RFM Analysis**: Mengukur **recency**, **frequency**, dan **monetary** untuk memahami segmentasi pelanggan berdasarkan perilaku pembelian.\n",
        "    - Menganalisis dataset untuk menghitung **frekuensi** dan **total pengeluaran**.\n",
        "    - Segmentasi pelanggan berdasarkan frekuensi pembelian dan total pengeluaran untuk mengidentifikasi kelompok yang paling menguntungkan.\n",
        "\n",
        "\n",
        "**3. \"Produk kategori mana yang memberikan kontribusi terbesar terhadap pendapatan perusahaan selama Q1 2017, dan apakah ada kategori dengan tingkat pengembalian produk (return rate) yang lebih tinggi?\"**\n",
        "\n",
        "- **Specific**: Fokus pada kontribusi pendapatan berdasarkan kategori produk selama Q1 2017.\n",
        "- **Measurable**: Menghitung kontribusi pendapatan dari tiap kategori produk dan mengukur tingkat pengembalian produk.\n",
        "- **Action-oriented**: Menyediakan informasi untuk perbaikan manajemen inventaris dan pengelolaan kategori produk.\n",
        "- **Relevant**: Membantu dalam memprioritaskan kategori produk untuk strategi pemasaran dan pengelolaan produk.\n",
        "- **Time-bound**: Fokus pada periode Q1 2017.\n",
        "\n",
        "**Teknik Analisis Lanjutan**:\n",
        "- **Clustering**: Mengelompokkan produk berdasarkan kategori dan kontribusi pendapatan untuk melihat pola kategori yang lebih menguntungkan.\n",
        "    - Menganalisis data dataset untuk menghitung kontribusi pendapatan berdasarkan kategori produk.\n",
        "    - Mengukur **tingkat pengembalian produk** dan mengidentifikasi kategori dengan **return rate** tinggi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-z4QGlO8DC1"
      },
      "source": [
        "## Import Semua Packages/Library yang Digunakan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVYwaObI8DC1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Sh51Xy8DC1"
      },
      "source": [
        "## Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXU2GBYu8DC1"
      },
      "source": [
        "### Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjCBk1BI8DC1"
      },
      "outputs": [],
      "source": [
        "# Baca data dari file CSV\n",
        "customers = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/customers_dataset.csv\")\n",
        "geolocation = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/geolocation_dataset.csv\")\n",
        "order_items = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/order_items_dataset.csv\")\n",
        "order_payments = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/order_payments_dataset.csv\")\n",
        "order_reviews = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/order_reviews_dataset.csv\")\n",
        "orders = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/orders_dataset.csv\", parse_dates=['order_purchase_timestamp', 'order_delivered_customer_date'])\n",
        "product_category_name_translation = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/product_category_name_translation.csv\")\n",
        "products = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/products_dataset.csv\")\n",
        "sellers = pd.read_csv(\"https://raw.githubusercontent.com/faarismuda/E-commerce-Analysis/main/Dataset/sellers_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**"
      ],
      "metadata": {
        "id": "3SMBsel6R3mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter orders dari tahun 2017\n",
        "orders['order_year'] = orders['order_purchase_timestamp'].dt.year\n",
        "orders_2017 = orders[orders['order_year'] == 2017]\n",
        "\n",
        "# Hitung waktu pengiriman\n",
        "orders_2017['delivery_duration'] = (orders_2017['order_delivered_customer_date'] - orders_2017['order_purchase_timestamp']).dt.days\n",
        "\n",
        "# Gabungkan orders dengan customers untuk mendapatkan informasi kota\n",
        "orders_customers = pd.merge(orders_2017, customers, on='customer_id', how='left')\n",
        "\n",
        "# Gabung dengan reviews untuk mendapatkan skor review\n",
        "orders_customers_reviews = pd.merge(orders_customers, reviews[['order_id', 'review_score']], on='order_id', how='left')\n",
        "\n",
        "# Gabung dengan geolocation untuk mendapatkan latitude dan longitude\n",
        "geolocation_unique = geolocation.drop_duplicates(subset=['geolocation_zip_code_prefix', 'geolocation_city'])\n",
        "merged_data = pd.merge(orders_customers_reviews, geolocation_unique,\n",
        "                       left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix',\n",
        "                       how='left')\n",
        "\n",
        "# Final dataset\n",
        "data_q1 = merged_data[['order_id', 'customer_city', 'delivery_duration', 'review_score',\n",
        "                          'geolocation_lat', 'geolocation_lng']]\n",
        "\n",
        "# Simpan dataset ke CSV\n",
        "data_q1.to_csv('data_q1.csv', index=False)\n",
        "\n",
        "data_q1.head()"
      ],
      "metadata": {
        "id": "Vl6ntxuQQ_zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**"
      ],
      "metadata": {
        "id": "E4phHp-rR-Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter orders dari tahun 2017\n",
        "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\n",
        "orders_2017 = orders[orders['order_purchase_timestamp'].dt.year == 2017]\n",
        "\n",
        "# Gabungkan orders_2017 dengan order_items\n",
        "data_q2 = orders_2017.merge(order_items, on='order_id', how='inner')\n",
        "\n",
        "# Gabungkan dengan customers untuk mendapatkan customer_unique_id\n",
        "data_q2 = data_q2.merge(customers, on='customer_id', how='inner')\n",
        "\n",
        "# Gabungkan dengan order_payments untuk validasi total pembayaran\n",
        "data_q2 = data_q2.merge(order_payments, on='order_id', how='left')\n",
        "\n",
        "# Tambahkan kolom total pengeluaran (price + freight_value)\n",
        "data_q2['total_spent'] = data_q2['price'] + data_q2['freight_value']\n",
        "\n",
        "# Final dataset\n",
        "data_q2 = data_q2[['customer_unique_id', 'order_id', 'order_purchase_timestamp',\n",
        "                               'price', 'freight_value', 'total_spent',\n",
        "                               'payment_value', 'payment_type']]\n",
        "\n",
        "# Simpan dataset ke CSV\n",
        "data_q2.to_csv('combined_dataset_2017.csv', index=False)\n",
        "\n",
        "data_q2.head()"
      ],
      "metadata": {
        "id": "CGNRzz-jR_AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3**"
      ],
      "metadata": {
        "id": "rrtoou5FR-Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3nD47e4R-4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMi6xGaDkbCi"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHSiqaZp8DC1"
      },
      "source": [
        "### Assessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**"
      ],
      "metadata": {
        "id": "sfuZgXxjS0mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Melihat informasi umum\n",
        "print(\"Informasi Dataset:\")\n",
        "print(data_q1.info())\n",
        "\n",
        "# 2. Statistik Deskriptif\n",
        "print(\"\\nStatistik Deskriptif:\")\n",
        "print(data_q1.describe(include='all'))\n",
        "\n",
        "# 3. Memeriksa nilai yang hilang\n",
        "print(\"\\nJumlah Nilai yang Hilang per Kolom:\")\n",
        "print(data_q1.isnull().sum())\n",
        "\n",
        "# 4. Memeriksa duplikasi\n",
        "print(\"\\nJumlah Baris Duplikat:\")\n",
        "print(data_q1.duplicated().sum())\n",
        "\n",
        "# 5. Melihat nilai unik dalam kolom kategorikal\n",
        "print(\"\\nNilai Unik Kolom 'customer_city':\")\n",
        "print(data_q1['customer_city'].unique())"
      ],
      "metadata": {
        "id": "KnvDClvvS5sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**"
      ],
      "metadata": {
        "id": "6zbu-YTiS2vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Melihat informasi umum\n",
        "print(\"Informasi Dataset:\")\n",
        "print(data_q2.info())\n",
        "\n",
        "# 2. Statistik Deskriptif\n",
        "print(\"\\nStatistik Deskriptif:\")\n",
        "print(data_q2.describe(include='all'))\n",
        "\n",
        "# 3. Memeriksa nilai yang hilang\n",
        "print(\"\\nJumlah Nilai yang Hilang per Kolom:\")\n",
        "print(data_q2.isnull().sum())\n",
        "\n",
        "# 4. Memeriksa duplikasi\n",
        "print(\"\\nJumlah Baris Duplikat:\")\n",
        "print(data_q2.duplicated().sum())\n",
        "\n",
        "# 5. Melihat nilai unik\n",
        "print(\"\\nCek Nilai Unik:\")\n",
        "print(data_q2.nunique())"
      ],
      "metadata": {
        "id": "3YJJPPCZS2Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3**"
      ],
      "metadata": {
        "id": "4kaSQRj3S21l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6K3Ut1ZS5pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dtxhAPrkhPL"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhN5R4hr8DC1"
      },
      "source": [
        "### Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**"
      ],
      "metadata": {
        "id": "vIZfmsofS_-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Menghapus duplikasi\n",
        "data_q1_cleaned = data_q1.drop_duplicates()\n",
        "print(\"\\nSetelah Menghapus Duplikasi, Total Baris:\", len(data_q1_cleaned))\n",
        "\n",
        "# 2. Menghapus baris dengan nilai yang hilang secara signifikan (jika diperlukan)\n",
        "# Misalnya, kita menghapus baris dengan `delivery_duration` atau `review_score` kosong\n",
        "data_q1_cleaned = data_q1_cleaned.dropna(subset=['delivery_duration', 'review_score'])\n",
        "\n",
        "# 3. Mengisi nilai yang hilang (jika sesuai)\n",
        "# Misalnya, untuk kolom koordinat geografis\n",
        "data_q1_cleaned['geolocation_lat'].fillna(data_q1_cleaned['geolocation_lat'].mean(), inplace=True)\n",
        "data_q1_cleaned['geolocation_lng'].fillna(data_q1_cleaned['geolocation_lng'].mean(), inplace=True)\n",
        "\n",
        "# 4. Memastikan tipe data sesuai\n",
        "# Kolom seperti `delivery_duration` dan `review_score` harus bertipe numerik\n",
        "data_q1_cleaned['delivery_duration'] = data_q1_cleaned['delivery_duration'].astype(float)\n",
        "data_q1_cleaned['review_score'] = data_q1_cleaned['review_score'].astype(float)\n",
        "\n",
        "# 5. Validasi nilai aneh atau outlier\n",
        "# Contoh: Durasi pengiriman negatif tidak masuk akal\n",
        "outliers = data_q1_cleaned[data_q1_cleaned['delivery_duration'] < 0]\n",
        "print(\"\\nBaris dengan Durasi Pengiriman Negatif (Outlier):\")\n",
        "print(outliers)\n",
        "\n",
        "# Menghapus outlier\n",
        "data_q1_cleaned = data_q1_cleaned[data_q1_cleaned['delivery_duration'] >= 0]\n",
        "\n",
        "# Simpan dataset yang sudah bersih\n",
        "data_q1_cleaned.to_csv('data_q1_cleaned.csv', index=False)\n",
        "\n",
        "print(\"\\nDataset telah dibersihkan. Total Baris Setelah Cleaning:\", len(data_q1_cleaned))\n"
      ],
      "metadata": {
        "id": "KsqUXvWGS62y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**"
      ],
      "metadata": {
        "id": "or8mXi-XTAIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Cleaning\n",
        "# a. Menghapus duplikasi (jika ada)\n",
        "data_q2_cleaned = data_q2.drop_duplicates()\n",
        "\n",
        "# b. Mengatasi missing values\n",
        "# Untuk kolom yang penting seperti `total_spent` atau `order_purchase_timestamp`, missing values akan dianalisis lebih lanjut\n",
        "print(\"\\nMissing values setelah pembersihan duplikasi:\")\n",
        "print(data_q2_cleaned.isnull().sum())\n",
        "\n",
        "# Jika ada missing values di kolom 'total_spent', kita bisa menghapus baris tersebut atau mengisi dengan mean/median (opsional)\n",
        "if data_q2_cleaned['total_spent'].isnull().sum() > 0:\n",
        "    data_q2_cleaned['total_spent'].fillna(data_q2_cleaned['total_spent'].median(), inplace=True)  # Contoh mengisi median\n",
        "\n",
        "# c. Konversi tipe data jika diperlukan\n",
        "data_q2_cleaned['order_purchase_timestamp'] = pd.to_datetime(data_q2_cleaned['order_purchase_timestamp'])  # Pastikan kolom datetime benar\n",
        "\n",
        "# d. Validasi konsistensi data: memastikan `total_spent` >= 0\n",
        "invalid_total_spent = data_q2_cleaned[data_q2_cleaned['total_spent'] < 0]\n",
        "if not invalid_total_spent.empty:\n",
        "    print(\"\\nBaris dengan 'total_spent' tidak valid (kurang dari 0):\")\n",
        "    print(invalid_total_spent)\n",
        "    # Menghapus baris dengan total_spent negatif\n",
        "    data_q2_cleaned = data_q2_cleaned[data_q2_cleaned['total_spent'] >= 0]\n",
        "\n",
        "# e. Validasi `payment_value` vs `total_spent`\n",
        "# Jika ada selisih yang terlalu besar, data bisa dianalisis lebih lanjut atau dihapus\n",
        "data_q2_cleaned['payment_difference'] = abs(data_q2_cleaned['payment_value'] - data_q2_cleaned['total_spent'])\n",
        "invalid_payments = data_q2_cleaned[data_q2_cleaned['payment_difference'] > 5]  # Toleransi selisih 5\n",
        "if not invalid_payments.empty:\n",
        "    print(\"\\nBaris dengan perbedaan signifikan antara 'payment_value' dan 'total_spent':\")\n",
        "    print(invalid_payments)\n",
        "\n",
        "# Opsional: Drop baris dengan payment_difference besar (jika dianggap noise)\n",
        "data_q2_cleaned = data_q2_cleaned[data_q2_cleaned['payment_difference'] <= 5]\n",
        "\n",
        "# f. Menambahkan kolom baru untuk analisis\n",
        "# Kolom 'month' untuk analisis musiman\n",
        "data_q2_cleaned['month'] = data_q2_cleaned['order_purchase_timestamp'].dt.month\n",
        "\n",
        "# Melihat hasil data setelah cleaning\n",
        "print(\"\\nData Setelah Cleaning:\")\n",
        "print(data_q2_cleaned.head())\n",
        "\n",
        "# Simpan hasil clean dataset (opsional)\n",
        "data_q2_cleaned.to_csv('data_q2_cleaned.csv', index=False)\n"
      ],
      "metadata": {
        "id": "kK4-yettS-QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3**"
      ],
      "metadata": {
        "id": "yOlZo4SETARe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZzXGQ9QAS-XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_5ejIqckiSP"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp-Y6wU38DC1"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW7WF2kr8DC1"
      },
      "source": [
        "### Explore ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th_Lzl2Fkj9O"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsyZjqak8DC2"
      },
      "source": [
        "## Visualization & Explanatory Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZxOiQ6n8DC2"
      },
      "source": [
        "### Pertanyaan 1:"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJ0rZR6CHpUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sr8AGUbHr1I"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25WWoQmJQRbX"
      },
      "source": [
        "### Pertanyaan 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0lCsvO8DC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0-36BDLklRg"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgHI7CiU8DC2"
      },
      "source": [
        "### Pertanyaan 3:"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vC98E6sHQV-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyqjQycjQXoB"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y4VUsmcYNZ5"
      },
      "source": [
        "## Analisis Lanjutan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWhnzsJGYUCO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WeHlCeX8DC2"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTcyR48Y8DC2"
      },
      "source": [
        "- Conclusion pertanyaan 1\n",
        "- Conclusion pertanyaan 2\n",
        "- Conclusion pertanyaan 3"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "972b3bf27e332e87b5379f2791f6ef9dfc79c71018c370b0d7423235e20fe4d7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}